{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-774f19c28c09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m     \u001b[0m_main\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tb'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\keras-gpu\\lib\\argparse.py\u001b[0m in \u001b[0;36mparse_args\u001b[1;34m(self, args, namespace)\u001b[0m\n\u001b[0;32m   1750\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1751\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'unrecognized arguments: %s'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1752\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1753\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\keras-gpu\\lib\\argparse.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, message)\u001b[0m\n\u001b[0;32m   2499\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_usage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2500\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'prog'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'message'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2501\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%(prog)s: error: %(message)s\\n'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda\\envs\\keras-gpu\\lib\\argparse.py\u001b[0m in \u001b[0;36mexit\u001b[1;34m(self, status, message)\u001b[0m\n\u001b[0;32m   2486\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2487\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_print_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2488\u001b[1;33m         \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2490\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSystemExit\u001b[0m: 2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--model_path MODEL_PATH] [-a ANCHORS_PATH]\n",
      "                             [-c CLASSES_PATH] [-t TEST_PATH] [-o OUTPUT_PATH]\n",
      "                             [-s SCORE_THRESHOLD] [-iou IOU_THRESHOLD]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\Jason\\AppData\\Roaming\\jupyter\\runtime\\kernel-3b6e1a49-3aeb-4200-abbc-dcec96c050a5.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "#! /usr/bin/env python\n",
    "\"\"\"Run a YOLO_v2 style detection model on test images.\"\"\"\n",
    "import argparse\n",
    "import colorsys\n",
    "import imghdr\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "from yad2k.models.keras_yolo import yolo_eval, yolo_head\n",
    "\n",
    "parser = argparse.ArgumentParser(\n",
    "    description='Run a YOLO_v2 style detection model on test images..')\n",
    "parser.add_argument(\n",
    "    '--model_path',\n",
    "    help='path to h5 model file containing body of a YOLO_v2 model',\n",
    "    default = 'model_data/yolo.h5')\n",
    "parser.add_argument(\n",
    "    '-a',\n",
    "    '--anchors_path',\n",
    "    help='path to anchors file, defaults to yolo_anchors.txt',\n",
    "    default='model_data/yolo_anchors.txt')\n",
    "parser.add_argument(\n",
    "    '-c',\n",
    "    '--classes_path',\n",
    "    help='path to classes file, defaults to coco_classes.txt',\n",
    "    default='model_data/coco_classes.txt')\n",
    "parser.add_argument(\n",
    "    '-t',\n",
    "    '--test_path',\n",
    "    help='path to directory of test images, defaults to images/',\n",
    "    default='images')\n",
    "parser.add_argument(\n",
    "    '-o',\n",
    "    '--output_path',\n",
    "    help='path to output test images, defaults to images/out',\n",
    "    default='images/out')\n",
    "parser.add_argument(\n",
    "    '-s',\n",
    "    '--score_threshold',\n",
    "    type=float,\n",
    "    help='threshold for bounding box scores, default .3',\n",
    "    default=.3)\n",
    "parser.add_argument(\n",
    "    '-iou',\n",
    "    '--iou_threshold',\n",
    "    type=float,\n",
    "    help='threshold for non max suppression IOU, default .5',\n",
    "    default=.5)\n",
    "\n",
    "\n",
    "def _main(args):\n",
    "    model_path = os.path.expanduser(args.model_path)\n",
    "    assert model_path.endswith('.h5'), 'Keras model must be a .h5 file.'\n",
    "    anchors_path = os.path.expanduser(args.anchors_path)\n",
    "    classes_path = os.path.expanduser(args.classes_path)\n",
    "    test_path = os.path.expanduser(args.test_path)\n",
    "    output_path = os.path.expanduser(args.output_path)\n",
    "\n",
    "    if not os.path.exists(output_path):\n",
    "        print('Creating output path {}'.format(output_path))\n",
    "        os.mkdir(output_path)\n",
    "\n",
    "    sess = K.get_session()  # TODO: Remove dependence on Tensorflow session.\n",
    "\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "        anchors = [float(x) for x in anchors.split(',')]\n",
    "        anchors = np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "    yolo_model = load_model(model_path)\n",
    "\n",
    "    # Verify model, anchors, and classes are compatible\n",
    "    num_classes = len(class_names)\n",
    "    num_anchors = len(anchors)\n",
    "    # TODO: Assumes dim ordering is channel last\n",
    "    model_output_channels = yolo_model.layers[-1].output_shape[-1]\n",
    "    assert model_output_channels == num_anchors * (num_classes + 5), \\\n",
    "        'Mismatch between model and given anchor and class sizes. ' \\\n",
    "        'Specify matching anchors and classes with --anchors_path and ' \\\n",
    "        '--classes_path flags.'\n",
    "    print('{} model, anchors, and classes loaded.'.format(model_path))\n",
    "\n",
    "    # Check if model is fully convolutional, assuming channel last order.\n",
    "    model_image_size = yolo_model.layers[0].input_shape[1:3]\n",
    "    is_fixed_size = model_image_size != (None, None)\n",
    "\n",
    "    # Generate colors for drawing bounding boxes.\n",
    "    hsv_tuples = [(x / len(class_names), 1., 1.)\n",
    "                  for x in range(len(class_names))]\n",
    "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "    colors = list(\n",
    "        map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\n",
    "            colors))\n",
    "    random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
    "    random.shuffle(colors)  # Shuffle colors to decorrelate adjacent classes.\n",
    "    random.seed(None)  # Reset seed to default.\n",
    "\n",
    "    # Generate output tensor targets for filtered bounding boxes.\n",
    "    # TODO: Wrap these backend operations with Keras layers.\n",
    "    yolo_outputs = yolo_head(yolo_model.output, anchors, len(class_names))\n",
    "    input_image_shape = K.placeholder(shape=(2, ))\n",
    "    boxes, scores, classes = yolo_eval(\n",
    "        yolo_outputs,\n",
    "        input_image_shape,\n",
    "        score_threshold=args.score_threshold,\n",
    "        iou_threshold=args.iou_threshold)\n",
    "\n",
    "\n",
    "    cap = cv2.VideoCapture('G:\\\\Unity\\\\AR_Boat\\\\Assets\\\\StreamingAssets\\\\vid_bigbuckbunny.mp4')\n",
    "\n",
    "    while(True):\n",
    "        ret, frame = cap.read()\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            out = cv2.imwrite('capture.jpg', frame)\n",
    "            break\n",
    "\n",
    "\n",
    "        # image_file = \"giraffe.jpg\"\n",
    "        # image = Image.open(os.path.join(test_path, image_file))\n",
    "        # if is_fixed_size:  # TODO: When resizing we can use minibatch input.\n",
    "        #     resized_image = image.resize(\n",
    "        #         tuple(reversed(model_image_size)), Image.BICUBIC)\n",
    "        #     image_data = np.array(resized_image, dtype='float32')\n",
    "        # else:\n",
    "        #     # Due to skip connection + max pooling in YOLO_v2, inputs must have\n",
    "        #     # width and height as multiples of 32.\n",
    "        #     new_image_size = (image.width - (image.width % 32),\n",
    "        #                         image.height - (image.height % 32))\n",
    "        #     resized_image = image.resize(new_image_size, Image.BICUBIC)\n",
    "        #     image_data = np.array(resized_image, dtype='float32')\n",
    "        #     print(image_data.shape)\n",
    "        resized_image = cv2.resize(frame, tuple(\n",
    "            reversed(model_image_size)), Image.BICUBIC)\n",
    "        image_data = np.array(resized_image, dtype='float32')\n",
    "        # image_data = np.array(frame, dtype='float32')\n",
    "        image_data /= 255.\n",
    "        image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "        out_boxes, out_scores, out_classes = sess.run(\n",
    "            [boxes, scores, classes],\n",
    "            feed_dict={\n",
    "                yolo_model.input: image_data,\n",
    "                input_image_shape: [frame.shape[1], frame.shape[0]],\n",
    "                K.learning_phase(): 0\n",
    "            })\n",
    "        # print('Found {} boxes for {}'.format(len(out_boxes), image_file))\n",
    "\n",
    "        font = ImageFont.truetype(\n",
    "            font='font/FiraMono-Medium.otf',\n",
    "            size=np.floor(3e-2 * frame.shape[1] + 0.5).astype('int32'))\n",
    "        thickness = (frame.shape[0] + frame.shape[1]) // 300\n",
    "\n",
    "        img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        for i, c in reversed(list(enumerate(out_classes))):\n",
    "            predicted_class = class_names[c]\n",
    "            box = out_boxes[i]\n",
    "            score = out_scores[i]\n",
    "\n",
    "            label = '{} {:.2f}'.format(predicted_class, score)\n",
    "\n",
    "            \n",
    "            draw = ImageDraw.Draw(img)\n",
    "            label_size = draw.textsize(label, font)\n",
    "\n",
    "            top, left, bottom, right = box\n",
    "            top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "            left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "            bottom = min(frame.shape[1], np.floor(bottom + 0.5).astype('int32'))\n",
    "            right = min(frame.shape[0], np.floor(right + 0.5).astype('int32'))\n",
    "            print(label, (left, top), (right, bottom))\n",
    "\n",
    "            if top - label_size[1] >= 0:\n",
    "                text_origin = np.array([left, top - label_size[1]])\n",
    "            else:\n",
    "                text_origin = np.array([left, top + 1])\n",
    "\n",
    "            offset = 250\n",
    "            # My kingdom for a good redistributable image drawing library.\n",
    "            for i in range(thickness):\n",
    "                draw.rectangle(\n",
    "                    [left + i + offset, top + i - offset,\n",
    "                        right - i + offset, bottom - i + offset],\n",
    "                    outline=colors[c])\n",
    "            draw.rectangle(\n",
    "                [tuple(text_origin), tuple(text_origin + label_size)],\n",
    "                fill=colors[c])\n",
    "            draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
    "            del draw\n",
    "        cv_img = cv2.cvtColor(np.asarray(img), cv2.COLOR_RGB2BGR)\n",
    "        cv2.imshow('frame', cv_img)\n",
    "        # image.save(os.path.join(output_path, image_file), quality=90)\n",
    "    sess.close()\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    %tb\n",
    "    _main(parser.parse_args())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'urllib' has no attribute 'urlopen'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-f043857862c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'http://96.10.1.168/mjpg/video.mjpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'urllib' has no attribute 'urlopen'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import urllib\n",
    "\n",
    "stream=urllib.urlopen('http://96.10.1.168/mjpg/video.mjpg')\n",
    "bytes=''\n",
    "while True:\n",
    "    bytes+=stream.read(1024)\n",
    "    a = bytes.find('\\xff\\xd8') # JPEG start\n",
    "    b = bytes.find('\\xff\\xd9') # JPEG end\n",
    "    if a!=-1 and b!=-1:\n",
    "        jpg = bytes[a:b+2] # actual image\n",
    "        bytes= bytes[b+2:] # other informations\n",
    "\n",
    "        # decode to colored image ( another option is cv2.IMREAD_GRAYSCALE )\n",
    "        img = cv2.imdecode(np.fromstring(jpg, dtype=np.uint8),cv2.IMREAD_COLOR) \n",
    "        cv2.imshow('Window name',img) # display image while receiving data\n",
    "        if cv2.waitKey(1) ==27: # if user hit esc\n",
    "            exit(0) # exit program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
